{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read an analysis report and for each violation, generate a sample patch for an incident\n",
    "\n",
    "## Workflow\n",
    "* For each analysis report\n",
    "    * For each violation\n",
    "        * Form a prompt \n",
    "            * If there are 2 or more incidents, use one of them as the prior/solved, where we find the latest state of file and use that as solved\n",
    "            * Use the extra contextual info we have in the prompt\n",
    "        * Send the prompt to LLM to get a Result\n",
    "        * Parse Result for:\n",
    "            * Explanation\n",
    "            * Code Patch\n",
    "        * Save the Explanation and Code Patch as separate files\n",
    "        * Later steps for verification\n",
    "            * Attempt to apply the code patch to the original file\n",
    "            * Use TreeSplitter to see if the is parseable\n",
    "            * If an error shows up, work with LLM to attempt to fix/apply/repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp resultb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from kyma_poc.report import Report\n",
    "from kyma_poc.scm import GitDiff\n",
    "\n",
    "import os \n",
    "\n",
    "class LLMResultB:\n",
    "    \"\"\" The intent of this class is to help us form several Prompt examples using a single application\n",
    "        which we have already migrated.  We are using this single application and picking a few \n",
    "        violations our analyzer finds and then will construct a few prompt examples to assess the\n",
    "        quality of response from a LLM\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" We expect to have 2 directories that represent the same example application\n",
    "            path_original_source is the original state of the application\n",
    "            path_solved_source is the solved state of the application (after it has been migrated)\n",
    "        \"\"\"\n",
    "        self.path_original_source = None\n",
    "        self.path_solved_source = None\n",
    "        self.path_to_report = None\n",
    "        self.report = None \n",
    "\n",
    "\n",
    "    def set_path_original_source(self, example_initial_git_path):\n",
    "        self.path_original_source = example_initial_git_path\n",
    "    \n",
    "    def set_path_solved_source(self, example_solved_git_path):\n",
    "        self.path_solved_source = example_solved_git_path\n",
    "\n",
    "    def parse_report(self, path_to_report):\n",
    "        self.report = Report(path_to_report).get_report()\n",
    "\n",
    "    def get_prompt_template(self):\n",
    "        with open(\"./templates/template_02.txt\", 'r') as f:\n",
    "            template = f.read()\n",
    "        return PromptTemplate.from_template(template)\n",
    "    \n",
    "    def _extract_diff(self, text: str):\n",
    "        try:\n",
    "            _, result = text.split(\"## Result\")\n",
    "            _, after = result.split(\"```diff\")\n",
    "            return after.split(\"```\")[0]\n",
    "        except Exception as e:\n",
    "            print(f\"_extract_diff Error: {e}\")\n",
    "            print(f\"text = \\n\\n{text}\\n\\n\")\n",
    "            return \"Error: Unable to extract diff\"   \n",
    "\n",
    "    def create_prompt(self, description, incidents, template):\n",
    "        # To form a prompt we need:\n",
    "        template = self.get_prompt_template()\n",
    "        print(f\"{len(incidents)} incidents:  {description}\\n\")\n",
    "\n",
    "    def get_original_code_snip(self, current_issue_filename, lineNumber, snipLength=30):\n",
    "        if lineNumber is None:\n",
    "            lineNumber = 0\n",
    "        try:\n",
    "            gd = GitDiff(self.path_original_source)\n",
    "            file_contents = gd.get_file_contents(current_issue_filename, \"HEAD\")\n",
    "            lines = file_contents.split(\"\\n\") \n",
    "            adjustment = 0\n",
    "            if len(lines) > 10: # Experiment to get a smaller code snip\n",
    "                startSnip = lineNumber-(snipLength/2)\n",
    "                if startSnip < 0:\n",
    "                    # Our 'window' has gone up against front of file\n",
    "                    # So we want to adjust the ending position to be a bit longer so we get the\n",
    "                    # full length of 'snipLength' \n",
    "                    adjustment = -1 * startSnip\n",
    "                    startSnip = 0 \n",
    "                endSnip = lineNumber+(snipLength/2)\n",
    "                endSnip = endSnip + adjustment\n",
    "                if endSnip > len(lines) - 1:\n",
    "                    endSnip = (len(lines) - 1)\n",
    "                startSnip = int(startSnip)\n",
    "                endSnip = int(endSnip)  \n",
    "                print(f\"startSnip={startSnip} endSnip={endSnip} adjustment={adjustment}\")\n",
    "                return \"\\n\".join(lines[startSnip: endSnip])\n",
    "            return \"\\n\".join(lines)\n",
    "        except Exception as e:\n",
    "            print(f\"get_original_code_snip Error: {e}\")\n",
    "            return \"\"\n",
    "        \n",
    "    def _update_uri(self, uri):\n",
    "        return uri.replace(\"file:///opt/input/source/\", \"\")\n",
    "     \n",
    "    def _ensure_output_dir_exists(self, output_dir):\n",
    "        try:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "        except OSError as error:\n",
    "            print(f\"Error creating directory {output_dir}: {error}\")\n",
    "            raise error\n",
    "\n",
    "    def _write_output(self, filename, content):\n",
    "        with open(filename, 'w') as f:\n",
    "            # We want to start each run with a clean file\n",
    "            f.truncate(0)\n",
    "            f.write(content)\n",
    "\n",
    "    def process(self, model_name=\"\", limit_to_rulesets=None, limit_to_violations=None):\n",
    "        if self.report is None:\n",
    "            raise Exception(\"No report to process.  Please parse a report first\")\n",
    "        if self.path_original_source is None:\n",
    "            raise Exception(\"No 'path_original_source'.  Please use set_path_original_source()\")\n",
    "        if self.path_solved_source is None:\n",
    "            raise Exception(\"No 'path_solved_source'.  Please use set_path_solved_source()\")\n",
    "\n",
    "        # Create result directory \n",
    "        self._ensure_output_dir_exists(\"./resultsB\")\n",
    "\n",
    "        for ruleset_name in self.report.keys():\n",
    "            if limit_to_rulesets is not None and ruleset_name not in limit_to_rulesets:\n",
    "                print(f\"Skipping {ruleset_name} as it is not in {limit_to_rulesets}\")\n",
    "                continue\n",
    "            ruleset = self.report[ruleset_name]\n",
    "            ruleset_name_display = ruleset_name.replace('/', '_')\n",
    "            print(f\"Processing {ruleset_name} {ruleset_name_display}\")\n",
    "            for count, key in enumerate(ruleset['violations']):\n",
    "                if limit_to_violations is not None and key not in limit_to_violations:     \n",
    "                    print(f\"Skipping {key} as it is not in {limit_to_violations}\")\n",
    "                    continue\n",
    "                \n",
    "\n",
    "                ###############################################################\n",
    "                # For each violation, we will form only 1 prompt\n",
    "                # If we have 2 incidents, we will use second as a 'solved' example, looking at the \n",
    "                # other repo which has the solved code present\n",
    "                # Otherwise we will just send the prompt with the first incident\n",
    "                #\n",
    "                # Note this only a POC so we are intentionally ignoring other incidents that\n",
    "                # would need to be solved.\n",
    "                ###############################################################\n",
    "                items = ruleset['violations'][key]\n",
    "\n",
    "                if len(items['incidents']) == 0:\n",
    "                    # No incidents so skip this iteration\n",
    "                    continue\n",
    "                \n",
    "                description = items['description']\n",
    "                current_issue_message = items['incidents'][0].get('message', None) \n",
    "                # Inclusion of line number on each line of CodeSnip causes some diffs to be \n",
    "                # incorrect from the LLM Result as it includes the line number thinking it's \n",
    "                # part of the text.\n",
    "                # Experimenting with NOT using CodeSnip and fetching file contents ourselves\n",
    "                #\n",
    "                #current_issue_original_code =  items['incidents'][0].get('codeSnip', None)    \n",
    "                lineNumber = items['incidents'][0].get('lineNumber', None)\n",
    "                current_issue_filename = self._update_uri(items['incidents'][0]['uri'])\n",
    "                current_issue_original_code = self.get_original_code_snip(current_issue_filename, lineNumber)\n",
    "               \n",
    "\n",
    "                solved_example_filename = \"\"\n",
    "                solved_example_diff = \"\" \n",
    "                if len(items['incidents']) > 1:\n",
    "                    example_lineNumber = items['incidents'][1].get('lineNumber', None)\n",
    "                    solved_example_filename = self._update_uri(items['incidents'][1]['uri'])\n",
    "                    try:\n",
    "                        gd = GitDiff(self.path_solved_source)\n",
    "                        commit_main = gd.get_commit_from_branch('main')\n",
    "                        commit_quarkus = gd.get_commit_from_branch('quarkus-migration')\n",
    "                        solved_example_diff = gd.get_patch_for_file(commit_main.hexsha, commit_quarkus.hexsha, solved_example_filename)\n",
    "                        #example_original_code = GitDiff(self.path_original_source).get_file_contents(example_original_filename)\n",
    "                    except Exception as e:\n",
    "                        print(f\"incidents < 1 processing - Error: {e}\")\n",
    "                        solved_example_diff = \"\"\n",
    "                        \n",
    "                prompt = self.get_prompt_template()\n",
    "                template_args = {\n",
    "                    \"description\": description,\n",
    "                    \"current_issue_filename\": current_issue_filename,\n",
    "                    \"current_issue_message\": current_issue_message,\n",
    "                    \"current_issue_original_code\": current_issue_original_code,\n",
    "                    \"solved_example_filename\": solved_example_filename,\n",
    "                    \"solved_example_diff\": solved_example_diff,\n",
    "                }\n",
    "                formatted_prompt = prompt.format(**template_args)\n",
    "                #self._write_output(f\"./results/{ruleset_name_display}_{key}_{count}_template.txt\", formatted_prompt)\n",
    "             \n",
    "                llm = ChatOpenAI(temperature=0.1, model_name=model_name)\n",
    "                chain = LLMChain(llm=llm, prompt=prompt)\n",
    "                result = chain.run(template_args)\n",
    "                result_diff = self._extract_diff(result)\n",
    "                \n",
    "                # Create result directory \n",
    "                self._ensure_output_dir_exists(f\"./resultsB/{model_name}\")\n",
    "                with open(f\"./resultsB/{model_name}/{ruleset_name_display}_{key}_{count}_full_run.md\", \"w\") as f:\n",
    "                    f.truncate(0)\n",
    "                    f.write(f\"# Ruleset Violation: '{ruleset_name}' '{key}'\\n\")\n",
    "                    f.write(f\"## Prompt:\\n\")\n",
    "                    f.write(f\"{formatted_prompt}\\n\")\n",
    "                    f.write(f\"\\n\\n## Output from LLM\\n\")\n",
    "                    f.write(f\"{result}\\n\\n\")\n",
    "\n",
    "                with open(f\"./resultsB/{model_name}/{ruleset_name_display}_{key}_{count}.diff\", \"w\") as f:\n",
    "                    f.truncate(0)\n",
    "                    f.write(result_diff)\n",
    "\n",
    "        print(f\"Process complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startSnip=0 endSnip=30 adjustment=15.0\n",
      "package com.redhat.coolstore.service;\n",
      "\n",
      "import java.io.Serializable;\n",
      "import java.util.HashMap;\n",
      "import java.util.HashSet;\n",
      "import java.util.Map;\n",
      "import java.util.Set;\n",
      "\n",
      "import javax.enterprise.context.ApplicationScoped;\n",
      "\n",
      "import com.redhat.coolstore.model.Promotion;\n",
      "import com.redhat.coolstore.model.ShoppingCart;\n",
      "import com.redhat.coolstore.model.ShoppingCartItem;\n",
      "\n",
      "@ApplicationScoped\n",
      "public class PromoService implements Serializable {\n",
      "\n",
      "    private static final long serialVersionUID = 2088590587856645568L;\n",
      "\n",
      "    private String name = null;\n",
      "\n",
      "    private Set<Promotion> promotionSet = null;\n",
      "\n",
      "    public PromoService() {\n",
      "\n",
      "        promotionSet = new HashSet<>();\n",
      "\n",
      "        promotionSet.add(new Promotion(\"329299\", .25));\n",
      "\n",
      "    }\n"
     ]
    }
   ],
   "source": [
    "# Experimenting with limiting how much of source file is returned centered on a given lineNumber\n",
    "example_initial_git_path = \"../data/coolstuff-javaee\"\n",
    "\n",
    "llmResult = LLMResultB()\n",
    "llmResult.set_path_original_source(example_initial_git_path)\n",
    "current_issue_filename = \"src/main/java/com/redhat/coolstore/service/PromoService.java\"\n",
    "lineNumber = 0\n",
    "snipLength = 30\n",
    "codeSnip = llmResult.get_original_code_snip(current_issue_filename, lineNumber, snipLength)\n",
    "print(f\"{codeSnip}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping eap7/websphere as it is not in ['quarkus/springboot']\n",
      "Skipping eap8/eap7 as it is not in ['quarkus/springboot']\n",
      "Skipping openshift as it is not in ['quarkus/springboot']\n",
      "Processing quarkus/springboot quarkus_springboot\n",
      "startSnip=0 endSnip=22 adjustment=15.0\n",
      "startSnip=0 endSnip=17 adjustment=3.0\n",
      "startSnip=3 endSnip=33 adjustment=0\n",
      "startSnip=0 endSnip=30 adjustment=15.0\n",
      "startSnip=0 endSnip=30 adjustment=15.0\n",
      "startSnip=0 endSnip=30 adjustment=15.0\n",
      "startSnip=0 endSnip=30 adjustment=15.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "example_solved_git_path = \"../data/coolstuff-quarkus\"\n",
    "example_initial_git_path = \"../data/coolstuff-javaee\"\n",
    "path_to_report = '../data/example_reports/coolstuff-javaee/output.yaml'\n",
    "#output_dir = './example/reports_B/coolstuff-javaee'\n",
    " \n",
    "#model_name = \"gpt-3.5-turbo-16k\" \n",
    "model_name=\"gpt-4-1106-preview\"\n",
    "\n",
    "llmResult = LLMResultB()\n",
    "llmResult.set_path_original_source(example_initial_git_path)\n",
    "llmResult.set_path_solved_source(example_solved_git_path)\n",
    "llmResult.parse_report(path_to_report)\n",
    "limit_to_rulesets = ['quarkus/springboot']\n",
    "limit_to_violations = ['cdi-to-quarkus-00040', 'cdi-to-quarkus-00050']\n",
    "#llmResult.process(model_name, limit_to_rulesets, limit_to_violations)\n",
    "llmResult.process(model_name, limit_to_rulesets)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
